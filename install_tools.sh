#!/bin/bash
# install_tools.sh - ä¸€é”®å®‰è£… s1hua æ‰€éœ€å·¥å…· (Linux/macOS)
# æ”¯æŒå›½å†…åŠ é€Ÿä»£ç†ï¼ˆghproxy.comï¼‰

set -e

SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
TOOL_LIST_DIR="$SCRIPT_DIR/toolList"
mkdir -p "$TOOL_LIST_DIR"

RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
NC='\033[0m'

log() { echo -e "${GREEN}[INFO]${NC} $1"; }
warn() { echo -e "${YELLOW}[WARN]${NC} $1"; }
error() { echo -e "${RED}[ERROR]${NC} $1" >&2; exit 1; }

# === è¯¢é—®æ˜¯å¦ä½¿ç”¨å›½å†…åŠ é€Ÿ ===
read -p "ğŸŒ æ˜¯å¦å¯ç”¨å›½å†… GitHub åŠ é€Ÿï¼Ÿ(Y/n): " USE_PROXY_INPUT
case ${USE_PROXY_INPUT:-Y} in
    [Nn]* ) USE_PROXY=false; BASE_URL="https://github.com";;
    * )     USE_PROXY=true;  BASE_URL="https://ghproxy.com/https://github.com";;
esac

if [ "$USE_PROXY" = true ]; then
    log "å·²å¯ç”¨å›½å†…åŠ é€Ÿä»£ç†: https://ghproxy.com"
else
    log "ä½¿ç”¨å®˜æ–¹ GitHub æº"
fi

# ä¸‹è½½å‡½æ•°ï¼ˆè‡ªåŠ¨æ‹¼æ¥ proxyï¼‰
get_release_url() {
    local repo=$1
    local pattern=$2  # å¦‚ "*linux_amd64.tar.gz"
    local api_url="https://api.github.com/repos/$repo/releases/latest"
    
    if [ "$USE_PROXY" = true ]; then
        # é€šè¿‡ä»£ç†è·å– release ä¿¡æ¯ï¼ˆæ³¨æ„ï¼šAPI ä¸èƒ½èµ° ghproxyï¼Œä½†å¯ä¸´æ—¶ç”¨ jsDelivr æˆ– raw.githubusercontentï¼‰
        # æ”¹ä¸ºç›´æ¥æ„é€  URLï¼ˆæ›´å¯é ï¼‰â€”â€” å¤šæ•°å·¥å…·å‘½åè§„åˆ™å›ºå®š
        echo "æš‚æ— æ³•é€šè¿‡ä»£ç†è·å– APIï¼Œå°†å°è¯•ç›´æ¥æ„é€ ä¸‹è½½é“¾æ¥..." >&2
        return 1
    else
        curl -s "$api_url" | grep "browser_download_url.*$pattern" | head -n1 | cut -d '"' -f 4
    fi
}

# æ›´å¯é æ–¹å¼ï¼šç›´æ¥æ„é€ ä¸‹è½½é“¾æ¥ï¼ˆå› å¤šæ•°å·¥å…·å‘½åè§„èŒƒï¼‰
construct_url() {
    local repo=$1
    local tag=$2      # å¦‚ "latest"
    local filename=$3 # å¦‚ "subfinder_linux_amd64.tar.gz"
    if [ "$USE_PROXY" = true ]; then
        echo "$BASE_URL/$repo/releases/$tag/download/$filename"
    else
        echo "https://github.com/$repo/releases/$tag/download/$filename"
    fi
}

download_and_extract() {
    local tool_name=$1
    local url=$2
    local dest_dir=$3
    local bin_name=$4

    log "æ­£åœ¨å®‰è£… $tool_name..."
    mkdir -p "$dest_dir"
    local tmp_file="/tmp/${tool_name}_latest$(echo $url | grep -o '\.[^.]*$')"
    
    curl -fL "$url" -o "$tmp_file" || error "ä¸‹è½½å¤±è´¥: $url"

    if [[ "$tmp_file" == *.zip ]]; then
        unzip -o "$tmp_file" -d "/tmp/${tool_name}_extract"
    else
        tar -xzf "$tmp_file" -C "/tmp" --strip-components=1 --wildcards "*/$bin_name*" 2>/dev/null || \
        tar -xzf "$tmp_file" -C "/tmp"
    fi

    local bin_path=$(find "/tmp" -name "$bin_name*" -type f ! -name "*.txt" ! -name "*.md" | head -n1)
    if [[ -n "$bin_path" ]]; then
        mv "$bin_path" "$dest_dir/$bin_name"
        chmod +x "$dest_dir/$bin_name"
        log "âœ… $tool_name å·²å®‰è£…"
    else
        error "æœªåœ¨å‹ç¼©åŒ…ä¸­æ‰¾åˆ° $bin_name"
    fi
    rm -rf "/tmp/${tool_name}_*" "$tmp_file"
}

# ========================
# å·¥å…·å®‰è£…ï¼ˆä½¿ç”¨æ„é€  URLï¼‰
# ========================

# subfinder - projectdiscovery/subfinder
SUBFINDER_URL=$(construct_url "projectdiscovery/subfinder" "latest" "subfinder_$(uname -s)_amd64.tar.gz")
download_and_extract "subfinder" "$SUBFINDER_URL" "$TOOL_LIST_DIR/subfinder" "subfinder"

# ksubdomain - boyhack/ksubdomain âœ… ä¿®æ­£é“¾æ¥
KS_URL=$(construct_url "boyhack/ksubdomain" "latest" "ksubdomain_$(uname -s)_amd64.tar.gz")
download_and_extract "ksubdomain" "$KS_URL" "$TOOL_LIST_DIR/ksubdomain" "ksubdomain"

# findomain - Edu4rdSHL/findomain
FD_URL=$(construct_url "Edu4rdSHL/findomain" "latest" "findomain-$(uname -s)-x86_64.zip")
download_and_extract "findomain" "$FD_URL" "$TOOL_LIST_DIR/findomain" "findomain"

# amass - OWASP/Amass
AMASS_URL=$(construct_url "OWASP/Amass" "latest" "amass_$(uname -s)_amd64.zip")
download_and_extract "amass" "$AMASS_URL" "$TOOL_LIST_DIR/amass" "amass"

# assetfinder - tomnomnom/assetfinder
AF_URL=$(construct_url "tomnomnom/assetfinder" "latest" "assetfinder_$(uname -s)_amd64.tar.gz")
download_and_extract "assetfinder" "$AF_URL" "$TOOL_LIST_DIR/assetfinder" "assetfinder"

# dnsx - projectdiscovery/dnsx
DNSX_URL=$(construct_url "projectdiscovery/dnsx" "latest" "dnsx_$(uname -s)_amd64.tar.gz")
download_and_extract "dnsx" "$DNSX_URL" "$TOOL_LIST_DIR/dnsx" "dnsx"

# OneForAll (Git cloneï¼Œå»ºè®®ä¸ç”¨ä»£ç†ï¼Œæˆ–ç”¨æˆ·è‡ªè¡Œé…ç½® git proxy)
if [ ! -d "$TOOL_LIST_DIR/OneForAll" ]; then
    if [ "$USE_PROXY" = true ]; then
        log "å…‹éš† OneForAllï¼ˆå¯èƒ½è¾ƒæ…¢ï¼Œè¯·è€å¿ƒç­‰å¾…ï¼‰..."
        git clone --depth=1 https://ghproxy.com/https://github.com/shmilylty/OneForAll.git "$TOOL_LIST_DIR/OneForAll"
    else
        git clone --depth=1 https://github.com/shmilylty/OneForAll.git "$TOOL_LIST_DIR/OneForAll"
    fi
else
    log "OneForAll å·²å­˜åœ¨ï¼Œè·³è¿‡å…‹éš†"
fi

log "ğŸ‰ æ‰€æœ‰å·¥å…·å®‰è£…å®Œæˆï¼"
log "ğŸ’¡ è¿è¡Œ: python3 s1hua.py --init åˆå§‹åŒ–é…ç½®"